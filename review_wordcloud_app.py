# -*- coding: utf-8 -*-
"""
ë¦¬ë·° ì›Œë“œ í´ë¼ìš°ë“œ + AI ë§ˆì¼€íŒ… ì¸ì‚¬ì´íŠ¸
ì‹¤í–‰: py -3.13 -m streamlit run review_wordcloud_app.py
"""
import io, re, textwrap, random
from collections import Counter
import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
from wordcloud import WordCloud
from kiwipiepy import Kiwi
import google.generativeai as genai

kiwi = Kiwi()

STOPWORDS = {
    "ê²ƒ","ìˆ˜","ë“±","ë”","ìœ„","ë•Œ","ì¤‘","ê³³","ê±¸","ë­","ì¢€","ì˜",
    "ê·¸","ì´","ì €","ë˜","ë°","ë¥¼","ì—","ì˜","ê°€","ì€","ëŠ”","ë¡œ",
    "ì™€","ê³¼","ë„","ë“¤","ë‚˜","ë•Œë¬¸","ê±°","ê²Œ","ë°","ì ","ë“¯",
    "ì •ë„","ì œ","ë‚´","ë„¤","ë‹˜","ë¶„","ê°œ","ë²ˆ","ë§","ë‹¤ë¥¸","ë‹¤ì‹œ",
    "í•˜ë‚˜","ì—¬ê¸°","ê±°ê¸°","ì–´ë””","ì–¸ì œ","ì–´ë–»ê²Œ","ì™œ","ë¬´ì—‡","ëˆ„êµ¬",
    "ìì²´","ì‚¬ìš©","êµ¬ë§¤","êµ¬ì…","ì£¼ë¬¸","ë°°ì†¡","ì œí’ˆ","ìƒí’ˆ","í›„ê¸°",
    "ê³„ì†","ë¶€ë¶„","ì •ë§","ì§„ì§œ","ì™„ì „","ë„ˆë¬´","ì•„ì£¼","ë§¤ìš°","ì—„ì²­",
    "ìƒê°","ëŠë‚Œ","ê¸°ë¶„","ì²˜ìŒ","ë§ˆìŒ",
}
POSITIVE_WORDS = {"ì¢‹ë‹¤","ì¢‹ì•„","ì¢‹ì€","ìµœê³ ","ë§Œì¡±","ì¶”ì²œ","í›Œë¥­","ì™„ë²½","ì¢‹ì•˜","ëŒ€ë°•","ì‚¬ë‘","ì˜ˆì˜","ê¹”ë”","ë¶€ë“œëŸ½","ì´‰ì´‰","ë³´ìŠµ","í–¥ê¸°","ê³ ê¸‰","ì‚°ëœ»","ê°œìš´","íš¨ê³¼","êµ¿","ê´œì°®","í¸í•˜","ë§˜ì—"}
NEGATIVE_WORDS = {"ë³„ë¡œ","ì‹«","ë‚˜ì˜","ì•„ì‰½","ë¶ˆë§Œ","ìµœì•…","í›„íšŒ","ì‹¤ë§","ì§œì¦","ìê·¹","ë”°ê°‘","ê±´ì¡°","ê±°ì¹ ","ì•„í”„","ë¶ˆí¸","ë¹„ì‹¸","ëƒ„ìƒˆ","ê°€ë µ","íŠ¸ëŸ¬ë¸”","ë¾°ë£¨ì§€","ì•Œë ˆë¥´ê¸°","ì•ˆì¢‹","ëª»ì“°"}

def extract_nouns(text):
    result = kiwi.analyze(text)
    return [t.form for t in result[0][0] if t.tag in ("NNG","NNP","SL") and len(t.form)>=2 and t.form not in STOPWORDS]

def classify_sentiment_by_text(text):
    pos = sum(1 for w in POSITIVE_WORDS if w in text)
    neg = sum(1 for w in NEGATIVE_WORDS if w in text)
    return "positive" if pos>neg else ("negative" if neg>pos else "neutral")

def get_korean_font_path():
    for p in ["C:/Windows/Fonts/malgun.ttf","C:/Windows/Fonts/gulim.ttc"]:
        try: fm.FontProperties(fname=p); return p
        except: continue
    for f in fm.fontManager.ttflist:
        if any(k in f.name.lower() for k in ["malgun","gulim","nanum"]): return f.fname
    return ""

KOREAN_FONT = get_korean_font_path()
REVIEW_COLS = ["ë¦¬ë·°","ë‚´ìš©","ë¦¬ë·°ë‚´ìš©","ë¦¬ë·° ë‚´ìš©","í›„ê¸°","review","content","text","comment","body"]
RATING_COLS = ["ë³„ì ","í‰ì ","ì ìˆ˜","rating","score","star","stars"]

def find_col(df, candidates):
    m = {c.strip().lower(): c for c in df.columns}
    for c in candidates:
        if c in m: return m[c]
    return None

def make_wc(freq, cmap="Set2"):
    if not freq:
        fig,ax=plt.subplots(figsize=(12,5)); ax.text(.5,.5,"ë°ì´í„° ì—†ìŒ",ha="center",va="center",fontsize=24,color="#666",transform=ax.transAxes); ax.set_facecolor("#0e1117"); fig.patch.set_facecolor("#0e1117"); ax.axis("off"); return fig
    wc=WordCloud(font_path=KOREAN_FONT or None,width=1200,height=600,background_color="#0e1117",colormap=cmap,max_words=80,prefer_horizontal=.7,min_font_size=14,max_font_size=120).generate_from_frequencies(freq)
    fig,ax=plt.subplots(figsize=(12,5)); ax.imshow(wc,interpolation="bilinear"); ax.axis("off"); fig.patch.set_facecolor("#0e1117"); plt.tight_layout(pad=0); return fig

def fig_bytes(fig):
    buf=io.BytesIO(); fig.savefig(buf,format="png",dpi=150,bbox_inches="tight",facecolor="#0e1117",edgecolor="none"); buf.seek(0); return buf.getvalue()

def show_kw_table(freq, top_n, label):
    items=freq.most_common(top_n)
    if not items: st.info(f"{label} í‚¤ì›Œë“œ ì—†ìŒ"); return
    tdf=pd.DataFrame(items,columns=["í‚¤ì›Œë“œ","ë¹ˆë„"]); tdf.index=range(1,len(tdf)+1); tdf.index.name="ìˆœìœ„"
    st.dataframe(tdf,use_container_width=True,height=min(38*len(tdf)+38,600))
    st.download_button(f"ğŸ“¥ {label} CSV",tdf.to_csv(encoding="utf-8-sig"),f"{label}_keywords.csv","text/csv",use_container_width=True,key=f"dl_{label}")

def build_prompt(pos_kw, neg_kw, neg_samples, total, pos_n, neg_n):
    pk=", ".join(f"{w}({c})" for w,c in pos_kw[:15])
    nk=", ".join(f"{w}({c})" for w,c in neg_kw[:15])
    ns="\n".join(f"- {r[:200]}" for r in neg_samples[:15])
    return textwrap.dedent(f"""\
    ë‹¹ì‹ ì€ ì „ì²œí›„ ë°ì´í„° ì‚¬ì´ì–¸í‹°ìŠ¤íŠ¸ì´ì ë§ˆì¼€íŒ… ì „ëµê°€ì…ë‹ˆë‹¤.

    ## ë¶„ì„ ë°ì´í„°
    - ì „ì²´ ë¦¬ë·°: {total:,}ê°œ / ê¸ì •: {pos_n:,}ê°œ / ë¶€ì •: {neg_n:,}ê°œ
    - ê¸ì • í‚¤ì›Œë“œ TOP15: {pk}
    - ë¶€ì • í‚¤ì›Œë“œ TOP15: {nk}

    ## ë¶€ì • ë¦¬ë·° ìƒ˜í”Œ
    {ns}

    ìœ„ ë°ì´í„° ê¸°ë°˜ìœ¼ë¡œ ì•„ë˜ 4ë‹¨ê³„ ë§ˆì¼€íŒ… ë³´ê³ ì„œë¥¼ í•œêµ­ì–´ ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.

    # Step 1: ë°ì´í„° íƒìƒ‰ ë° ì¹´í…Œê³ ë¦¬ ì •ì˜
    1. ì œí’ˆ/ì„œë¹„ìŠ¤ ì¹´í…Œê³ ë¦¬ ì •ì˜
    2. í•µì‹¬ í‚¤ì›Œë“œ TOP10 â†’ [ê¸ì •ì  íŠ¹ì§•(USP)] vs [ë¶€ì •ì  ë¶ˆë§Œ(Pain Point)] ë¶„ë¥˜

    # Step 2: ë™ì  ë§ˆì¼€íŒ… ì¸ì‚¬ì´íŠ¸ ë„ì¶œ (3ê°€ì§€ ì „ëµ)
    1. [ê°•ì  ê·¹ëŒ€í™”] ê¸ì • í‚¤ì›Œë“œ â†’ ê´‘ê³  ì¹´í”¼ / ë©”ì¸ í›„í‚¹ ë¬¸êµ¬ ì œì•ˆ
    2. [ìœ„ê¸° ë° ì´íƒˆ ë°©ì§€] ë¶€ì • í‚¤ì›Œë“œ â†’ ìƒì„¸í˜ì´ì§€ í•´ëª…Â·ë³´ì™„ ì „ëµ
    3. [ì‚¬ìš© ë§¥ë½ ë¶„ì„(TPO)] ì‚¬ìš© ìƒí™© ë¶„ì„ â†’ íƒ€ê²Ÿ ë§ˆì¼€íŒ… ë°©í–¥

    # Step 3: ì·¨ì•½ ì§€ì  ì‹¬ì¸µ ë¶„ì„ (Voice of Customer)
    1. ë¬¸ì œ í‚¤ì›Œë“œ 2~3ê°œ ì„ ì •
    2. ìœ„ ë¦¬ë·° ì›ë¬¸ ì¸ìš©í•˜ë©° êµ¬ì²´ì  ë¶ˆë§Œ ë¶„ì„
    3. ë§ˆì¼€í„°ê°€ ë†“ì¹˜ê¸° ì‰¬ìš´ ë””í…Œì¼í•œ ë¶ˆë§Œ í¬ì¸íŠ¸ ìš”ì•½

    # Step 4: ì‹¤í–‰ ê°€ëŠ¥í•œ ì•¡ì…˜ í”Œëœ
    - ì¦‰ì‹œ ì‹¤í–‰ ê°€ëŠ¥í•œ ê´‘ê³  ì†Œì¬ ì•„ì´ë””ì–´ 3ê°€ì§€ (ì´ë¯¸ì§€/ì˜ìƒ ì»¨ì…‰ + ê´‘ê³  ì¹´í”¼)
    """)

# ============================================================
st.set_page_config(page_title="ë¦¬ë·° ì›Œë“œ í´ë¼ìš°ë“œ + AI ì¸ì‚¬ì´íŠ¸", page_icon="â˜ï¸", layout="wide")
st.markdown("""<style>
@import url('https://fonts.googleapis.com/css2?family=Noto+Sans+KR:wght@400;600;700;900&display=swap');
html,body,[class*="css"]{font-family:'Noto Sans KR',sans-serif}
.main-header{text-align:center;padding:2rem 0 .5rem}
.main-header h1{font-size:2.6rem;font-weight:900;background:linear-gradient(135deg,#667eea,#764ba2);-webkit-background-clip:text;-webkit-text-fill-color:transparent}
.main-header p{color:#9ca3af;font-size:1.05rem}
.sc{border-radius:14px;padding:1.2rem;text-align:center;border:1px solid rgba(99,102,241,.25)}
.sc.p{background:linear-gradient(135deg,#064e3b,#065f46)}.sc.n{background:linear-gradient(135deg,#4c0519,#881337)}.sc.a{background:linear-gradient(135deg,#1e1b4b,#312e81)}
.sn{font-size:2rem;font-weight:900;color:#e0e7ff}.sl{color:#9ca3af;font-size:.85rem;margin-top:.2rem}
</style>""", unsafe_allow_html=True)
st.markdown('<div class="main-header"><h1>â˜ï¸ ë¦¬ë·° ì›Œë“œ í´ë¼ìš°ë“œ + AI ì¸ì‚¬ì´íŠ¸</h1><p>ë¦¬ë·° íŒŒì¼ ì—…ë¡œë“œ â†’ ê¸ì •Â·ë¶€ì • ì›Œë“œ í´ë¼ìš°ë“œ â†’ AI ë§ˆì¼€íŒ… ë³´ê³ ì„œ</p></div>', unsafe_allow_html=True)

with st.sidebar:
    st.markdown("### ğŸ”‘ Gemini API Key")
    api_key = st.text_input("API Key", type="password", help="https://aistudio.google.com/apikey")
    st.markdown("---")
    st.markdown("### âš™ï¸ ì„¤ì •")
    max_words = st.slider("ìµœëŒ€ ë‹¨ì–´ ìˆ˜",30,200,80,step=10)
    min_wl = st.slider("ìµœì†Œ ê¸€ì ìˆ˜",1,5,2)
    top_n = st.slider("ìƒìœ„ í‚¤ì›Œë“œ ìˆ˜",10,50,20,step=5)
    st.markdown("---")
    st.markdown("### ğŸš« ì¶”ê°€ ë¶ˆìš©ì–´")
    csw = st.text_area("ì œì™¸ ë‹¨ì–´ (ì‰¼í‘œ êµ¬ë¶„)", placeholder="ë°°ì†¡, ì£¼ë¬¸")

uploaded = st.file_uploader("ë¦¬ë·° íŒŒì¼ ì—…ë¡œë“œ (.xlsx, .csv)", type=["xlsx","csv"])

if uploaded:
    try:
        if uploaded.name.endswith(".xlsx"): df=pd.read_excel(uploaded,engine="openpyxl")
        else:
            raw=uploaded.read()
            for enc in ["utf-8-sig","utf-8","cp949","euc-kr"]:
                try: td=raw.decode(enc); break
                except: continue
            else: td=raw.decode("utf-8",errors="replace")
            df=pd.read_csv(io.StringIO(td))
    except Exception as e: st.error(f"íŒŒì¼ ì˜¤ë¥˜: {e}"); st.stop()

    st.success(f"âœ… **{uploaded.name}** â€” {len(df):,}í–‰")
    rc=find_col(df,REVIEW_COLS); rtc=find_col(df,RATING_COLS)
    if not rc: rc=st.selectbox("ë¦¬ë·° ì»¬ëŸ¼ ì„ íƒ:",df.columns.tolist())
    else: st.info(f"ğŸ“Œ ë¦¬ë·°: **{rc}**"+(f" | ë³„ì : **{rtc}**" if rtc else ""))

    if rtc:
        with st.sidebar:
            st.markdown("---"); st.markdown("### â­ ë³„ì  ê¸°ì¤€")
            pmin=st.slider("ê¸ì • ìµœì†Œ",1,5,4); nmax=st.slider("ë¶€ì • ìµœëŒ€",1,5,2)

    esw={w.strip() for w in csw.split(",") if w.strip()} if csw else set()

    if st.button("ğŸš€ ì›Œë“œ í´ë¼ìš°ë“œ + ì¸ì‚¬ì´íŠ¸ ìƒì„±",type="primary",use_container_width=True):
        rdf=df[[rc]].copy(); rdf["text"]=rdf[rc].fillna("").astype(str)
        if rtc:
            df[rtc]=pd.to_numeric(df[rtc],errors="coerce"); rdf["rating"]=df[rtc]
            rdf["sent"]=rdf["rating"].apply(lambda r: "positive" if r>=pmin else ("negative" if r<=nmax else "neutral"))
        else: rdf["sent"]=rdf["text"].apply(classify_sentiment_by_text)

        pos_rv=rdf[rdf["sent"]=="positive"]["text"].tolist()
        neg_rv=rdf[rdf["sent"]=="negative"]["text"].tolist()
        all_rv=rdf["text"].tolist()

        def extr(rvs):
            ns=[]
            for r in rvs:
                c=re.sub(r"[^\w\sê°€-í£a-zA-Z]"," ",r)
                ns.extend(n for n in extract_nouns(c) if len(n)>=min_wl and n not in esw)
            return Counter(ns)

        prog=st.progress(0,"ë¶„ì„ ì¤‘...")
        prog.progress(10,"ê¸ì • ë¶„ì„..."); pf=extr(pos_rv)
        prog.progress(50,"ë¶€ì • ë¶„ì„..."); nf=extr(neg_rv)
        prog.progress(90,"ì „ì²´ ë¶„ì„..."); af=extr(all_rv)
        prog.empty()

        c1,c2,c3=st.columns(3)
        c1.markdown(f'<div class="sc a"><div class="sn">{len(all_rv):,}</div><div class="sl">ì „ì²´</div></div>',unsafe_allow_html=True)
        c2.markdown(f'<div class="sc p"><div class="sn">{len(pos_rv):,}</div><div class="sl">ê¸ì •</div></div>',unsafe_allow_html=True)
        c3.markdown(f'<div class="sc n"><div class="sn">{len(neg_rv):,}</div><div class="sl">ë¶€ì •</div></div>',unsafe_allow_html=True)
        st.markdown("---")

        tw,ti=st.tabs(["â˜ï¸ ì›Œë“œ í´ë¼ìš°ë“œ","ğŸ§  AI ë§ˆì¼€íŒ… ì¸ì‚¬ì´íŠ¸"])

        with tw:
            st.markdown("## ğŸ˜Š ê¸ì • ì›Œë“œ í´ë¼ìš°ë“œ")
            fp=make_wc(dict(pf.most_common(max_words)),"winter"); st.pyplot(fp,use_container_width=True)
            st.download_button("ğŸ“¥ ê¸ì • PNG",fig_bytes(fp),"pos_wc.png","image/png",use_container_width=True,key="dp"); plt.close(fp)
            with st.expander("ğŸ“Š ê¸ì • í‚¤ì›Œë“œ",expanded=False): show_kw_table(pf,top_n,"ê¸ì •")
            st.markdown("---")

            st.markdown("## ğŸ˜  ë¶€ì • ì›Œë“œ í´ë¼ìš°ë“œ")
            fn=make_wc(dict(nf.most_common(max_words)),"autumn"); st.pyplot(fn,use_container_width=True)
            st.download_button("ğŸ“¥ ë¶€ì • PNG",fig_bytes(fn),"neg_wc.png","image/png",use_container_width=True,key="dn"); plt.close(fn)
            with st.expander("ğŸ“Š ë¶€ì • í‚¤ì›Œë“œ",expanded=False): show_kw_table(nf,top_n,"ë¶€ì •")
            st.markdown("---")

            st.markdown("## ğŸŒ ì „ì²´ ì›Œë“œ í´ë¼ìš°ë“œ")
            fa=make_wc(dict(af.most_common(max_words)),"Set2"); st.pyplot(fa,use_container_width=True)
            st.download_button("ğŸ“¥ ì „ì²´ PNG",fig_bytes(fa),"all_wc.png","image/png",use_container_width=True,key="da"); plt.close(fa)
            with st.expander("ğŸ“Š ì „ì²´ í‚¤ì›Œë“œ",expanded=False): show_kw_table(af,top_n,"ì „ì²´")

        with ti:
            if not api_key:
                st.warning("âš ï¸ ì‚¬ì´ë“œë°”ì—ì„œ **Gemini API Key**ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                st.markdown("> ğŸ”‘ [Google AI Studio](https://aistudio.google.com/apikey)ì—ì„œ ë¬´ë£Œ ë°œê¸‰ ê°€ëŠ¥")
            else:
                st.markdown("## ğŸ§  AI ë§ˆì¼€íŒ… ì¸ì‚¬ì´íŠ¸ ë³´ê³ ì„œ")
                sn=neg_rv[:15] if len(neg_rv)<=15 else random.sample(neg_rv,15)
                prompt=build_prompt(pf.most_common(15),nf.most_common(15),sn,len(all_rv),len(pos_rv),len(neg_rv))
                with st.spinner("ğŸ¤– Gemini AI ë¶„ì„ ì¤‘..."):
                    try:
                        genai.configure(api_key=api_key)
                        model=genai.GenerativeModel("gemini-2.0-flash")
                        resp=model.generate_content(prompt)
                        st.markdown(resp.text)
                        st.download_button("ğŸ“¥ ë³´ê³ ì„œ ë‹¤ìš´ë¡œë“œ (.md)",resp.text.encode("utf-8"),"marketing_insight.md","text/markdown",use_container_width=True,key="dl_rpt")
                    except Exception as e:
                        st.error(f"âŒ ì˜¤ë¥˜: {e}")
                        st.info("API Keyë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
